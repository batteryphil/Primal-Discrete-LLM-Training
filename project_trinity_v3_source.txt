================================================================================
PROJECT TRINITY: V3.0.0 "PRIME RICH" - FULL SOURCE CODE
================================================================================
Generated: February 9, 2026
Author: BatteryPhil
Target: 4-bit Prime Harmonic Large Language Model (13-Value Grid)

Table of Contents:
1.  [Documentation] README.md (Updated)
2.  [Documentation] BENCHMARKS.md (Updated)
3.  [Documentation] PAPER.md (Updated)
4.  [Engine: C++] src/engine/trinity.h (Prime Rich LUT)
5.  [Engine: C++] src/engine/cpu_kernel.cpp (Random Data Generation)
6.  [Engine: C++] src/engine/gpu_kernel.cu (Constant Memory LUT)
7.  [Engine: C++] src/engine/main.cpp (Benchmarker)

================================================================================
FILE 1: README.md (Excerpt)
--------------------------------------------------------------------------------
> **[V3.0.0 Prime Rich Update]**
> Building on the valid 4-bit architecture of V2.0.0, **V3.0.0** expands the 
> quantization grid to include **13 distinct Prime Harmonic values**.

================================================================================
FILE 2: src/engine/trinity.h
--------------------------------------------------------------------------------
WHAT: Header defining the "Prime Rich" LUT.
WHY:  Populates the 9 previously empty 4-bit slots with $\pm 1/7, \pm 1/11, \dots$
--------------------------------------------------------------------------------

#pragma once
#include <vector>
#include <string>

// Unpacking LUT: 4-bit Nibble -> Prime Value
// Grid: V3.0.0 "Prime Rich"
const float LUT[16] = {
    0.0f,               // 0x0: Sparsity
    1.0f, -1.0f,        // 0x1, 0x2: Unity
    0.5f, -0.5f,        // 0x3, 0x4: 1/2
    0.333333f, -0.333333f, // 0x5, 0x6: 1/3
    0.2f, -0.2f,        // 0x7, 0x8: 1/5
    0.142857f, -0.142857f, // 0x9, 0xA: 1/7
    0.090909f, -0.090909f, // 0xB, 0xC: 1/11
    0.076923f, -0.076923f, // 0xD, 0xE: 1/13
    0.0f                // 0xF: Reserved
};

struct Tensor {
  std::string name;
  int rows, cols;
  float scale = 1.0f;               
  std::vector<uint8_t> data_packed; 
  std::vector<float> data_fp32;     
};

class TrinityEngine {
public:
  std::vector<Tensor> weights;
  bool use_gpu = false;
  void load(const std::string &path);
  void forward(const std::vector<float> &input, std::vector<float> &output);
  void cpu_forward(const std::vector<float> &input, std::vector<float> &output);
  void gpu_forward(const std::vector<float> &input, std::vector<float> &output);
};

================================================================================
FILE 3: src/engine/cpu_kernel.cpp
--------------------------------------------------------------------------------
WHAT: 4-bit CPU Kernel with Full-Range Testing.
WHY:  Fills dummy data with 0x00-0xFF to exercise all LUT entries.
--------------------------------------------------------------------------------

#include "trinity.h"
#include <omp.h>
#include <iostream>

void TrinityEngine::load(const std::string &path) {
  // ...
  Tensor t;
  t.rows = 2048;
  t.cols = 2048;
  t.scale = 0.002f; 
  size_t num_weights = t.rows * t.cols;
  size_t packed_size = num_weights / 2; 
  t.data_packed.resize(packed_size);
  
  // Fill with random data (0x00 - 0xFF)
  for (size_t i = 0; i < packed_size; ++i) {
      t.data_packed[i] = rand() % 256;
  }

  t.data_fp32.resize(num_weights);
  // ... (Unpacking for validation omitted) ...
  weights.push_back(t);
}

void TrinityEngine::cpu_forward(const std::vector<float> &input,
                                std::vector<float> &output) {
  const Tensor &W = weights[0];
  output.resize(W.rows);
#pragma omp parallel for schedule(static)
  for (long long i = 0; i < W.rows; ++i) {
    float sum = 0.0f;
    for (int k = 0; k < W.cols; ++k) {
      sum += W.data_fp32[i * W.cols + k] * input[k];
    }
    output[i] = sum * W.scale; 
  }
}

================================================================================
FILE 4: src/engine/gpu_kernel.cu
--------------------------------------------------------------------------------
WHAT: 4-bit CUDA Kernel with Prime Rich LUT.
WHY:  Syncs Constant Memory `d_LUT` with the new values.
--------------------------------------------------------------------------------

#include "trinity.h"
#include <cuda_runtime.h>

// Global LUT in Constant Memory (16 values)
// Grid: V3.0.0 "Prime Rich"
__constant__ float d_LUT[16] = {
    0.0f,               // 0x0
    1.0f, -1.0f,        // 0x1, 0x2
    0.5f, -0.5f,        // 0x3, 0x4
    0.333333f, -0.333333f, // 0x5, 0x6
    0.2f, -0.2f,        // 0x7, 0x8
    0.142857f, -0.142857f, // 0x9, 0xA
    0.090909f, -0.090909f, // 0xB, 0xC
    0.076923f, -0.076923f, // 0xD, 0xE
    0.0f                // 0xF
};

__global__ void
matmul_4bit_kernel(const uint8_t *__restrict__ W_packed,
                   const float *__restrict__ Input,
                   float *__restrict__ Output,
                   float scale,
                   int Rows, int Cols) {
  int row = blockIdx.x * blockDim.x + threadIdx.x;
  if (row >= Rows) return;

  float sum = 0.0f;
  int packed_cols = Cols / 2; // 2 weights per byte

  for (int k = 0; k < packed_cols; ++k) {
    uint8_t packed_byte = W_packed[row * packed_cols + k];
    float w0 = d_LUT[(packed_byte >> 4) & 0x0F];
    float w1 = d_LUT[(packed_byte >> 0) & 0x0F];

    int input_idx = k * 2;
    sum += w0 * Input[input_idx + 0];
    sum += w1 * Input[input_idx + 1];
  }
  Output[row] = sum * scale; 
}
