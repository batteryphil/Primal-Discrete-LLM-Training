================================================================================
PROJECT PRIMAL: V3.0.0 "PRIME RICH" - FULL SOURCE CODE
================================================================================
Generated: February 9, 2026
Author: BatteryPhil
Target: 4-bit Prime Harmonic Large Language Model (13-Value Grid)

Table of Contents:
1.  [Documentation] README.md (Updated)
2.  [Documentation] BENCHMARKS.md (Updated)
3.  [Documentation] PAPER.md (Updated)
4.  [Engine: C++] src/engine/primal.h (Prime Rich LUT)
5.  [Engine: C++] src/engine/cpu_kernel.cpp (PrimalEngine)
6.  [Engine: C++] src/engine/gpu_kernel.cu (PrimalEngine)
7.  [Engine: C++] src/engine/main.cpp (Entry Point)
8.  [Engine: Script] src/engine/build.bat
9.  [Engine: Script] run_test.bat

================================================================================
FILE 1: README.md
--------------------------------------------------------------------------------
# ‚üÅ PRIMAL: The "Homebrew" Prime Rich LLM
**PRIMAL-1.1B** is a proof-of-concept **4-bit Prime Harmonic** model evolved from TinyLlama.

================================================================================
FILE 4: src/engine/primal.h
--------------------------------------------------------------------------------
#pragma once
#include <vector>
#include <string>

// V3.0.0 "Prime Rich" LUT: 4-bit Nibble -> Prime Value
const float LUT[16] = {
    0.0f,               // 0x0: Sparsity
    1.0f, -1.0f,        // 0x1, 0x2: Unity
    0.5f, -0.5f,        // 0x3, 0x4: 1/2
    0.333333f, -0.333333f, // 0x5, 0x6: 1/3
    0.2f, -0.2f,        // 0x7, 0x8: 1/5
    0.142857f, -0.142857f, // 0x9, 0xA: 1/7
    0.090909f, -0.090909f, // 0xB, 0xC: 1/11
    0.076923f, -0.076923f, // 0xD, 0xE: 1/13
    0.0f                // 0xF: Reserved
};

struct Tensor {
    std::string name;
    int rows, cols;
    float scale = 1.0f;             
    std::vector<uint8_t> data_packed; 
    std::vector<float> data_fp32;     
};

class PrimalEngine {
public:
    std::vector<Tensor> weights;
    bool use_gpu = false;
    void load(const std::string &path);
    void forward(const std::vector<float> &input, std::vector<float> &output);
    void cpu_forward(const std::vector<float> &input, std::vector<float> &output);
    void gpu_forward(const std::vector<float> &input, std::vector<float> &output);
};

================================================================================
FILE 5: src/engine/cpu_kernel.cpp
--------------------------------------------------------------------------------
#include "primal.h"
#include <omp.h>
#include <iostream>
#include <cstdlib>

void PrimalEngine::load(const std::string &path) {
    std::cout << "[Primal] Initializing Dummy Model (V3.0.0 Prime Rich)..." << std::endl;
    Tensor t;
    t.rows = 2048;
    t.cols = 2048;
    t.scale = 0.002f; 
    size_t num_weights = t.rows * t.cols;
    size_t packed_size = num_weights / 2; // 4-bit = 2 weights per byte
    t.data_packed.resize(packed_size);
    
    // Fill with random data (0x00 - 0xFF) to test full LUT range
    for (size_t i = 0; i < packed_size; ++i) {
        t.data_packed[i] = rand() % 256;
    }

    t.data_fp32.resize(num_weights);
    // Unpack for CPU validation
    #pragma omp parallel for
    for (long long i = 0; i < (long long)packed_size; ++i) {
        uint8_t byte = t.data_packed[i];
        size_t idx = i * 2;
        t.data_fp32[idx + 0] = LUT[(byte >> 4) & 0x0F]; // High Nibble
        t.data_fp32[idx + 1] = LUT[(byte >> 0) & 0x0F]; // Low Nibble
    }
    weights.push_back(t);
}

void PrimalEngine::forward(const std::vector<float> &input, std::vector<float> &output) {
    if (use_gpu) gpu_forward(input, output);
    else cpu_forward(input, output);
}

void PrimalEngine::cpu_forward(const std::vector<float> &input, std::vector<float> &output) {
    if (weights.empty()) return;
    const Tensor &W = weights[0];
    output.resize(W.rows);
    #pragma omp parallel for schedule(static)
    for (long long i = 0; i < W.rows; ++i) {
        float sum = 0.0f;
        for (int k = 0; k < W.cols; ++k) {
            sum += W.data_fp32[i * W.cols + k] * input[k];
        }
        output[i] = sum * W.scale; 
    }
}

================================================================================
FILE 6: src/engine/gpu_kernel.cu
--------------------------------------------------------------------------------
#include "primal.h"
#include <cuda_runtime.h>
#include <cstdio>

#define CHECK_CUDA(call) { \
    cudaError_t err = call; \
    if (err != cudaSuccess) { \
        printf("CUDA Error: %s at line %d\n", cudaGetErrorString(err), __LINE__); \
        exit(1); \
    } \
}

// Global LUT in Constant Memory
__constant__ float d_LUT[16] = {
    0.0f, 1.0f, -1.0f, 0.5f, -0.5f, 0.333333f, -0.333333f,
    0.2f, -0.2f, 0.142857f, -0.142857f, 0.090909f, -0.090909f,
    0.076923f, -0.076923f, 0.0f
};

__global__ void matmul_4bit_kernel(const uint8_t *__restrict__ W_packed,
                                   const float *__restrict__ Input,
                                   float *__restrict__ Output,
                                   float scale,
                                   int Rows, int Cols) {
    int row = blockIdx.x * blockDim.x + threadIdx.x;
    if (row >= Rows) return;

    float sum = 0.0f;
    int packed_cols = Cols / 2; 

    for (int k = 0; k < packed_cols; ++k) {
        uint8_t packed_byte = W_packed[row * packed_cols + k];
        float w0 = d_LUT[(packed_byte >> 4) & 0x0F];
        float w1 = d_LUT[(packed_byte >> 0) & 0x0F];
        int input_idx = k * 2;
        sum += w0 * Input[input_idx + 0];
        sum += w1 * Input[input_idx + 1];
    }
    Output[row] = sum * scale; 
}

void PrimalEngine::gpu_forward(const std::vector<float> &input, std::vector<float> &output) {
    if (weights.empty()) return;
    const Tensor &W = weights[0];
    
    uint8_t *d_W; float *d_In, *d_Out;
    size_t w_bytes = W.data_packed.size();
    size_t in_bytes = input.size() * sizeof(float);
    size_t out_bytes = W.rows * sizeof(float);

    CHECK_CUDA(cudaMalloc(&d_W, w_bytes));
    CHECK_CUDA(cudaMalloc(&d_In, in_bytes));
    CHECK_CUDA(cudaMalloc(&d_Out, out_bytes));

    CHECK_CUDA(cudaMemcpy(d_W, W.data_packed.data(), w_bytes, cudaMemcpyHostToDevice));
    CHECK_CUDA(cudaMemcpy(d_In, input.data(), in_bytes, cudaMemcpyHostToDevice));

    int threads = 256;
    int blocks = (W.rows + threads - 1) / threads;
    matmul_4bit_kernel<<<blocks, threads>>>(d_W, d_In, d_Out, W.scale, W.rows, W.cols);
    CHECK_CUDA(cudaDeviceSynchronize());

    output.resize(W.rows);
    CHECK_CUDA(cudaMemcpy(output.data(), d_Out, out_bytes, cudaMemcpyDeviceToHost));
    
    cudaFree(d_W); cudaFree(d_In); cudaFree(d_Out);
}

================================================================================
FILE 7: src/engine/main.cpp
--------------------------------------------------------------------------------
#include "primal.h"
#include <iostream>
#include <chrono>

int main(int argc, char **argv) {
    bool use_gpu = (argc > 1 && std::string(argv[1]) == "gpu");
    std::cout << "Starting Project PRIMAL V3.0.0 [Mode: " << (use_gpu ? "GPU" : "CPU") << "]" << std::endl;

    PrimalEngine engine;
    engine.use_gpu = use_gpu;
    engine.load("dummy_path");

    std::vector<float> input(2048, 1.0f);
    std::vector<float> output;

    // Warmup
    engine.forward(input, output);

    // Benchmark
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 10; ++i) engine.forward(input, output);
    auto end = std::chrono::high_resolution_clock::now();
    
    std::chrono::duration<double> elapsed = end - start;
    std::cout << "Avg Time: " << (elapsed.count() / 10.0) * 1000 << " ms" << std::endl;
    std::cout << "Output[0]: " << output[0] << std::endl;
    return 0;
}

================================================================================
FILE 8: src/engine/build.bat
--------------------------------------------------------------------------------
@echo off
if not exist "bin" mkdir bin
echo Building CPU...
cl /EHsc /O2 /openmp main.cpp cpu_kernel.cpp gpu_dummy.cpp /Fe:bin/primal_cpu.exe
echo Building GPU...
nvcc -O3 -o bin/primal_gpu.exe main.cpp cpu_kernel.cpp gpu_kernel.cu
echo Done.

================================================================================
FILE 9: run_test.bat
--------------------------------------------------------------------------------
@echo off
cd src/engine
call build.bat
if exist bin\primal_cpu.exe (
    echo Running CPU Benchmark...
    bin\primal_cpu.exe
)
if exist bin\primal_gpu.exe (
    echo Running GPU Benchmark...
    bin\primal_gpu.exe gpu
)
pause
