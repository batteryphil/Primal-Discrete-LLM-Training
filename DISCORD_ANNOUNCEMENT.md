# Project PRIMAL: The 11GB VRAM Challenge
**"Training a 0.1B 1.58-bit LLM on a single GTX 1080 Ti"**

I am currently running an experiment to democratize LLM pre-training by proving it can be done on consumer-grade hardware from 2017.

## The Constraints
*   **Hardware:** Single NVIDIA GTX 1080 Ti (11GB VRAM).
*   **Target:** 0.1B Parameter Model (Proof of Concept).
*   **Precision:** 1.58-bit (Tertiary Weights $\{-1, 0, 1\}$).
*   **Optimization:** Must maintain >5,000 Tokens/sec throughput.

## The Architecture: "Poltergeist" (Ghost-0.1B)
We faced severe stability issues with standard BitNet b1.58 training (loss divergence >9.0). We solved this with a new quantization strategy called **"Poltergeist"**:

1.  **Decoupled Flipping:**
    *   Weights usually flip signs *during the backward pass* in standard Straight-Through Estimators (STE). This caused massive gradient noise on small batches.
    *   **Solution:** We accumulate "votes" (sign directions) in an `int8` buffer during the backward pass but **only apply the flips** during the optimizer step. This aligns the discrete jump with the optimizer's trajectory.

2.  **Adaptive Flip Probability:**
    *   Instead of a hard STE, we use a stochastic process where the probability of a weight flipping $\{0 \to \pm 1\}$ scales with the layer's `Ghost Scale` (a learnable scalar representing the layer's dynamic range).
    *   **Result:** Layers become "quieter" as they converge (Scale $< 0.4$), naturally annealing the learning process.

3.  **The "Harmonic Bridge":**
    *   Standard quantization grid: $\{-1, 0, 1\}$.
    *   Our grid: Added $\pm 0.666$ ($2/3$) to the quantization LUT to act as a bridge for gradients that are *almost* strong enough to flip but would otherwise be crushed to zero.

## Current Progress
*   **Step:** 12,492 (and counting).
*   **Loss:** **5.4** (Down from 9.2).
*   **Perplexity (WikiText-2):** ~1,050 (Validation).
*   **Throughput:** **5,767 Tokens/sec** on 1080 Ti.
*   **Memory:** **10.37 GB** / 11.00 GB (Pinned).

## "Salad Test" (Semantic Emergence)
We run a live generation test every 50 steps. The model has moved from random characters to coherent English concepts:
> *Step 11,650: "The future of AI is to evaluate video system damages in a field. Pents of the National Encyclopedia of Technology Co."*

## Why This Matters
If this stabilizes, it proves that meaningful pre-training of tertiary-weight models is possible on <12GB VRAM without needing an H100 cluster.

**Repo:** [Link to your GitHub]
**Status:** Ongoing.

*(Generated by Project PRIMAL Telemetry)*
